{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Loan Approval Prediction Analysis\n",
        "\n",
        "## Step 1: Data Exploration & Understanding\n",
        "\n",
        "**Objective:** Understand the dataset structure, features, and basic characteristics\n",
        "\n",
        "**Key concepts covered:**\n",
        "- Loading and inspecting data\n",
        "- Understanding data types and shapes\n",
        "- Basic statistical summaries\n",
        "- Identifying potential data quality issues\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìö Libraries imported successfully!\n",
            "üéØ Ready to explore our loan approval dataset!\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configure plotting style\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"Libraries imported successfully\")\n",
        "print(\"Ready to analyze the loan approval dataset\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1 Loading the Dataset\n",
        "\n",
        "**Key Concept:** Always start by loading your data and getting a first look at its structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Dataset loaded successfully!\n",
            "üìä Dataset shape: (4269, 13)\n",
            "   - 4,269 rows (loan applications)\n",
            "   - 13 columns (features + target)\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset\n",
        "# Note: The CSV contains spaces after commas which we'll need to handle\n",
        "df = pd.read_csv('loan_approval_dataset.csv')\n",
        "\n",
        "print(\"Dataset loaded successfully\")\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"   - {df.shape[0]:,} rows (loan applications)\")\n",
        "print(f\"   - {df.shape[1]} columns (features + target)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2 First Look at the Data\n",
        "\n",
        "**Key Concept:** Use `.head()`, `.info()`, and `.describe()` to understand your data structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç First 5 rows of our dataset:\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loan_id</th>\n",
              "      <th>no_of_dependents</th>\n",
              "      <th>education</th>\n",
              "      <th>self_employed</th>\n",
              "      <th>income_annum</th>\n",
              "      <th>loan_amount</th>\n",
              "      <th>loan_term</th>\n",
              "      <th>cibil_score</th>\n",
              "      <th>residential_assets_value</th>\n",
              "      <th>commercial_assets_value</th>\n",
              "      <th>luxury_assets_value</th>\n",
              "      <th>bank_asset_value</th>\n",
              "      <th>loan_status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>9600000</td>\n",
              "      <td>29900000</td>\n",
              "      <td>12</td>\n",
              "      <td>778</td>\n",
              "      <td>2400000</td>\n",
              "      <td>17600000</td>\n",
              "      <td>22700000</td>\n",
              "      <td>8000000</td>\n",
              "      <td>Approved</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Not Graduate</td>\n",
              "      <td>Yes</td>\n",
              "      <td>4100000</td>\n",
              "      <td>12200000</td>\n",
              "      <td>8</td>\n",
              "      <td>417</td>\n",
              "      <td>2700000</td>\n",
              "      <td>2200000</td>\n",
              "      <td>8800000</td>\n",
              "      <td>3300000</td>\n",
              "      <td>Rejected</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>9100000</td>\n",
              "      <td>29700000</td>\n",
              "      <td>20</td>\n",
              "      <td>506</td>\n",
              "      <td>7100000</td>\n",
              "      <td>4500000</td>\n",
              "      <td>33300000</td>\n",
              "      <td>12800000</td>\n",
              "      <td>Rejected</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>No</td>\n",
              "      <td>8200000</td>\n",
              "      <td>30700000</td>\n",
              "      <td>8</td>\n",
              "      <td>467</td>\n",
              "      <td>18200000</td>\n",
              "      <td>3300000</td>\n",
              "      <td>23300000</td>\n",
              "      <td>7900000</td>\n",
              "      <td>Rejected</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>Not Graduate</td>\n",
              "      <td>Yes</td>\n",
              "      <td>9800000</td>\n",
              "      <td>24200000</td>\n",
              "      <td>20</td>\n",
              "      <td>382</td>\n",
              "      <td>12400000</td>\n",
              "      <td>8200000</td>\n",
              "      <td>29400000</td>\n",
              "      <td>5000000</td>\n",
              "      <td>Rejected</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   loan_id  no_of_dependents      education self_employed  income_annum  \\\n",
              "0        1                 2       Graduate            No       9600000   \n",
              "1        2                 0   Not Graduate           Yes       4100000   \n",
              "2        3                 3       Graduate            No       9100000   \n",
              "3        4                 3       Graduate            No       8200000   \n",
              "4        5                 5   Not Graduate           Yes       9800000   \n",
              "\n",
              "   loan_amount  loan_term  cibil_score  residential_assets_value  \\\n",
              "0     29900000         12          778                   2400000   \n",
              "1     12200000          8          417                   2700000   \n",
              "2     29700000         20          506                   7100000   \n",
              "3     30700000          8          467                  18200000   \n",
              "4     24200000         20          382                  12400000   \n",
              "\n",
              "   commercial_assets_value  luxury_assets_value  bank_asset_value loan_status  \n",
              "0                 17600000             22700000           8000000    Approved  \n",
              "1                  2200000              8800000           3300000    Rejected  \n",
              "2                  4500000             33300000          12800000    Rejected  \n",
              "3                  3300000             23300000           7900000    Rejected  \n",
              "4                  8200000             29400000           5000000    Rejected  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Display first few rows\n",
        "print(\"First 5 rows of the dataset:\")\n",
        "print(\"=\" * 40)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìã Dataset Information:\n",
            "==============================\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4269 entries, 0 to 4268\n",
            "Data columns (total 13 columns):\n",
            " #   Column                    Non-Null Count  Dtype \n",
            "---  ------                    --------------  ----- \n",
            " 0   loan_id                   4269 non-null   int64 \n",
            " 1   no_of_dependents          4269 non-null   int64 \n",
            " 2   education                 4269 non-null   object\n",
            " 3   self_employed             4269 non-null   object\n",
            " 4   income_annum              4269 non-null   int64 \n",
            " 5   loan_amount               4269 non-null   int64 \n",
            " 6   loan_term                 4269 non-null   int64 \n",
            " 7   cibil_score               4269 non-null   int64 \n",
            " 8   residential_assets_value  4269 non-null   int64 \n",
            " 9   commercial_assets_value   4269 non-null   int64 \n",
            " 10  luxury_assets_value       4269 non-null   int64 \n",
            " 11  bank_asset_value          4269 non-null   int64 \n",
            " 12  loan_status               4269 non-null   object\n",
            "dtypes: int64(10), object(3)\n",
            "memory usage: 433.7+ KB\n"
          ]
        }
      ],
      "source": [
        "# Check data types and missing values\n",
        "print(\"Dataset Information:\")\n",
        "print(\"=\" * 25)\n",
        "df.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üßπ Cleaning column names...\n",
            "Before: ['loan_id', 'no_of_dependents', 'education', 'self_employed', 'income_annum', 'loan_amount', 'loan_term', 'cibil_score', 'residential_assets_value', 'commercial_assets_value', 'luxury_assets_value', 'bank_asset_value', 'loan_status']\n",
            "After: ['loan_id', 'no_of_dependents', 'education', 'self_employed', 'income_annum', 'loan_amount', 'loan_term', 'cibil_score', 'residential_assets_value', 'commercial_assets_value', 'luxury_assets_value', 'bank_asset_value', 'loan_status']\n",
            "\n",
            "‚úÖ Column names cleaned!\n"
          ]
        }
      ],
      "source": [
        "# Clean column names (remove extra spaces)\n",
        "print(\"Cleaning column names...\")\n",
        "print(\"Before:\", list(df.columns))\n",
        "\n",
        "df.columns = df.columns.str.strip()\n",
        "print(\"After:\", list(df.columns))\n",
        "\n",
        "print(\"\\nColumn names cleaned successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.3 Understanding Our Features\n",
        "\n",
        "**Key Concept:** Categorize features into different types for appropriate handling.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üéØ Feature Categories:\n",
            "=========================\n",
            "üÜî Identifier: ['loan_id']\n",
            "üìù Categorical: ['education', 'self_employed']\n",
            "üî¢ Numerical: ['no_of_dependents', 'income_annum', 'loan_amount', 'loan_term', 'cibil_score', 'residential_assets_value', 'commercial_assets_value', 'luxury_assets_value', 'bank_asset_value']\n",
            "üéØ Target: loan_status\n"
          ]
        }
      ],
      "source": [
        "# Categorize our features\n",
        "print(\"Feature Categories:\")\n",
        "print(\"=\" * 20)\n",
        "\n",
        "# Identifier\n",
        "identifier = ['loan_id']\n",
        "print(f\"Identifier: {identifier}\")\n",
        "\n",
        "# Categorical features\n",
        "categorical_features = ['education', 'self_employed']\n",
        "print(f\"Categorical: {categorical_features}\")\n",
        "\n",
        "# Numerical features\n",
        "numerical_features = ['no_of_dependents', 'income_annum', 'loan_amount', 'loan_term', \n",
        "                     'cibil_score', 'residential_assets_value', 'commercial_assets_value', \n",
        "                     'luxury_assets_value', 'bank_asset_value']\n",
        "print(f\"Numerical: {numerical_features}\")\n",
        "\n",
        "# Target variable\n",
        "target = 'loan_status'\n",
        "print(f\"Target variable: {target}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.4 Target Variable Analysis\n",
        "\n",
        "**Key Concept:** Always understand your target variable first - this is what we're trying to predict!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üéØ Target Variable Analysis:\n",
            "==============================\n",
            "loan_status\n",
            "Approved    2656\n",
            "Rejected    1613\n",
            "Name: count, dtype: int64\n",
            "loan_status\n",
            "Approved    62.215976\n",
            "Rejected    37.784024\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Analyze target variable\n",
        "print(\"üéØ Target Variable Analysis:\")\n",
        "print(\"=\" * 30)\n",
        "\n",
        "# Clean target variable (remove extra spaces)\n",
        "df['loan_status'] = df['loan_status'].str.strip()\n",
        "\n",
        "# Value counts\n",
        "target_counts = df['loan_status'].value_counts()\n",
        "target_percentage = df['loan_status'].value_counts(normalize=True) * 100\n",
        "\n",
        "print(target_counts)\n",
        "print(target_percentage)\n",
        "\n",
        "# print(\"Counts:\")\n",
        "# for status, count in target_counts.items():\n",
        "#     percentage = target_percentage[status]\n",
        "#     print(f\"  {status}: {count:,} ({percentage:.1f}%)\")\n",
        "\n",
        "# # Calculate imbalance ratio\n",
        "# imbalance_ratio = target_counts.max() / target_counts.min()\n",
        "# print(f\"\\n‚öñÔ∏è  Class Imbalance Ratio: {imbalance_ratio:.2f}:1\")\n",
        "\n",
        "# if imbalance_ratio > 1.5:\n",
        "#     print(\"‚ö†Ô∏è  Dataset is imbalanced - we'll need to address this later!\")\n",
        "# else:\n",
        "#     print(\"‚úÖ Dataset is relatively balanced\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 2: Data Cleaning\n",
        "\n",
        "**Objective:** Clean and prepare the data for analysis\n",
        "\n",
        "**Key concepts covered:**\n",
        "- Detecting and handling outliers\n",
        "- Data quality validation techniques  \n",
        "- Cleaning categorical variables\n",
        "- Preparing clean data for modeling\n",
        "\n",
        "**Importance:** Data quality directly impacts model performance. Poor quality input leads to unreliable results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Missing Values Check\n",
        "\n",
        "**Key Concept:** Always verify if you have missing data - even if initial check showed none!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ùì Missing Values Analysis:\n",
            "==============================\n",
            "‚úÖ No missing values found!\n",
            "   This is rare in real-world data - great dataset!\n",
            "\n",
            "üîç Checking for other missing value representations:\n",
            "‚úÖ education: Clean\n",
            "‚úÖ self_employed: Clean\n",
            "‚úÖ loan_status: Clean\n"
          ]
        }
      ],
      "source": [
        "# Comprehensive missing values analysis\n",
        "print(\"Missing Values Analysis:\")\n",
        "print(\"=\" * 25)\n",
        "\n",
        "missing_values = df.isnull().sum()\n",
        "missing_percentage = (missing_values / len(df)) * 100\n",
        "\n",
        "missing_summary = pd.DataFrame({\n",
        "    'Missing Count': missing_values,\n",
        "    'Missing %': missing_percentage.round(2)\n",
        "})\n",
        "\n",
        "# Only show columns with missing values\n",
        "missing_summary = missing_summary[missing_summary['Missing Count'] > 0]\n",
        "\n",
        "if len(missing_summary) > 0:\n",
        "    print(\"Found missing values:\")\n",
        "    print(missing_summary)\n",
        "    print(\"\\nThese will need to be handled...\")\n",
        "else:\n",
        "    print(\"No missing values found\")\n",
        "    print(\"   This is rare in real-world data\")\n",
        "\n",
        "# Also check for other representations of missing data\n",
        "print(\"\\nChecking for other missing value representations:\")\n",
        "for col in df.select_dtypes(include=['object']).columns:\n",
        "    unique_vals = df[col].unique()\n",
        "    suspicious_vals = [val for val in unique_vals if \n",
        "                      str(val).lower() in ['nan', 'null', 'none', '', ' ', 'na', '?', '-']]\n",
        "    if suspicious_vals:\n",
        "        print(f\"   {col}: Found suspicious values: {suspicious_vals}\")\n",
        "    else:\n",
        "        print(f\"   {col}: Clean\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Outlier Detection and Analysis\n",
        "\n",
        "**Key Concept:** Outliers can significantly impact model performance. We need to identify and decide how to handle them.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üö® Outlier Detection Analysis:\n",
            "===================================\n",
            "\n",
            "üìä income_annum:\n",
            "   Range: 200,000 to 9,900,000\n",
            "   Valid range: -4,500,000 to 14,700,000\n",
            "   Outliers: 0 (0.0%)\n",
            "   ‚úÖ No outliers detected\n",
            "\n",
            "üìä loan_amount:\n",
            "   Range: 300,000 to 39,500,000\n",
            "   Valid range: -13,000,000 to 42,200,000\n",
            "   Outliers: 0 (0.0%)\n",
            "   ‚úÖ No outliers detected\n",
            "\n",
            "üìä cibil_score:\n",
            "   Range: 300 to 900\n",
            "   Valid range: 10 to 1,190\n",
            "   Outliers: 0 (0.0%)\n",
            "   ‚úÖ No outliers detected\n",
            "\n",
            "üìä loan_term:\n",
            "   Range: 2 to 20\n",
            "   Valid range: -9 to 31\n",
            "   Outliers: 0 (0.0%)\n",
            "   ‚úÖ No outliers detected\n"
          ]
        }
      ],
      "source": [
        "# Outlier detection using IQR method\n",
        "print(\"üö® Outlier Detection Analysis:\")\n",
        "print(\"=\" * 35)\n",
        "\n",
        "def detect_outliers_iqr(df, column):\n",
        "    \"\"\"Detect outliers using Interquartile Range (IQR) method\"\"\"\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    \n",
        "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
        "    return outliers, lower_bound, upper_bound\n",
        "\n",
        "# Analyze key numerical features for outliers\n",
        "key_features = ['income_annum', 'loan_amount', 'cibil_score', 'loan_term']\n",
        "\n",
        "outlier_summary = {}\n",
        "\n",
        "for feature in key_features:\n",
        "    outliers, lower, upper = detect_outliers_iqr(df, feature)\n",
        "    outlier_percentage = (len(outliers) / len(df)) * 100\n",
        "    \n",
        "    outlier_summary[feature] = {\n",
        "        'count': len(outliers),\n",
        "        'percentage': outlier_percentage,\n",
        "        'lower_bound': lower,\n",
        "        'upper_bound': upper\n",
        "    }\n",
        "    \n",
        "    print(f\"\\nüìä {feature}:\")\n",
        "    print(f\"   Range: {df[feature].min():,.0f} to {df[feature].max():,.0f}\")\n",
        "    print(f\"   Valid range: {lower:,.0f} to {upper:,.0f}\")\n",
        "    print(f\"   Outliers: {len(outliers):,} ({outlier_percentage:.1f}%)\")\n",
        "    \n",
        "    if outlier_percentage > 5:\n",
        "        print(f\"   ‚ö†Ô∏è  High number of outliers - investigate further\")\n",
        "    elif outlier_percentage > 0:\n",
        "        print(f\"   ‚úÖ Manageable number of outliers\")\n",
        "    else:\n",
        "        print(f\"   ‚úÖ No outliers detected\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 Categorical Data Cleaning\n",
        "\n",
        "**Key Concept:** Clean categorical variables by removing extra spaces and checking for inconsistent values.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìù Categorical Data Cleaning:\n",
            "==============================\n",
            "\n",
            "üîç Cleaning education:\n",
            "   Before: [' Graduate' ' Not Graduate']\n",
            "   After:  ['Graduate' 'Not Graduate']\n",
            "   Value counts:\n",
            "     Graduate: 2,144 (50.2%)\n",
            "     Not Graduate: 2,125 (49.8%)\n",
            "\n",
            "üîç Cleaning self_employed:\n",
            "   Before: [' No' ' Yes']\n",
            "   After:  ['No' 'Yes']\n",
            "   Value counts:\n",
            "     Yes: 2,150 (50.4%)\n",
            "     No: 2,119 (49.6%)\n",
            "\n",
            "‚úÖ Categorical data cleaned!\n"
          ]
        }
      ],
      "source": [
        "# Clean categorical features\n",
        "print(\"Categorical Data Cleaning:\")\n",
        "print(\"=\" * 25)\n",
        "\n",
        "# Clean categorical features (remove extra spaces and standardize)\n",
        "for feature in categorical_features:\n",
        "    print(f\"\\nCleaning {feature}:\")\n",
        "    \n",
        "    # Before cleaning\n",
        "    print(f\"   Before: {df[feature].unique()}\")\n",
        "    \n",
        "    # Clean the feature\n",
        "    df[feature] = df[feature].str.strip()\n",
        "    \n",
        "    # After cleaning\n",
        "    print(f\"   After:  {df[feature].unique()}\")\n",
        "    \n",
        "    # Check value counts\n",
        "    print(f\"   Value counts:\")\n",
        "    for value, count in df[feature].value_counts().items():\n",
        "        percentage = (count / len(df)) * 100\n",
        "        print(f\"     {value}: {count:,} ({percentage:.1f}%)\")\n",
        "\n",
        "print(\"\\nCategorical data cleaned successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.4 Data Quality Validation\n",
        "\n",
        "**Key Concept:** Validate that our data makes business sense - catch logical inconsistencies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Data Quality Validation:\n",
            "==============================\n",
            "1. Income vs Loan Amount Validation:\n",
            "   High risk loans (>5x income): 0 (0.0%)\n",
            "\n",
            "2. CIBIL Score Validation:\n",
            "   Invalid CIBIL scores (<300 or >900): 0\n",
            "\n",
            "3. Loan Term Validation:\n",
            "   Unusual loan terms (<1 or >30 years): 0\n",
            "\n",
            "4. Asset Values Validation:\n",
            "   Negative residential_assets_value: 28\n",
            "\n",
            "‚úÖ Data quality validation complete!\n"
          ]
        }
      ],
      "source": [
        "# Business logic validation\n",
        "print(\"Data Quality Validation:\")\n",
        "print(\"=\" * 25)\n",
        "\n",
        "# Check for logical inconsistencies\n",
        "print(\"1. Income vs Loan Amount Validation:\")\n",
        "# Calculate loan-to-income ratio\n",
        "df['loan_to_income_ratio'] = df['loan_amount'] / df['income_annum']\n",
        "high_ratio = df[df['loan_to_income_ratio'] > 5]  # Loan > 5x income\n",
        "print(f\"   High risk loans (>5x income): {len(high_ratio):,} ({(len(high_ratio)/len(df)*100):.1f}%)\")\n",
        "\n",
        "print(\"\\n2. CIBIL Score Validation:\")\n",
        "invalid_cibil = df[(df['cibil_score'] < 300) | (df['cibil_score'] > 900)]\n",
        "print(f\"   Invalid CIBIL scores (<300 or >900): {len(invalid_cibil):,}\")\n",
        "if len(invalid_cibil) > 0:\n",
        "    print(f\"   Range found: {df['cibil_score'].min()} to {df['cibil_score'].max()}\")\n",
        "\n",
        "print(\"\\n3. Loan Term Validation:\")\n",
        "unusual_terms = df[(df['loan_term'] < 1) | (df['loan_term'] > 30)]\n",
        "print(f\"   Unusual loan terms (<1 or >30 years): {len(unusual_terms):,}\")\n",
        "if len(unusual_terms) > 0:\n",
        "    print(f\"   Range found: {df['loan_term'].min()} to {df['loan_term'].max()}\")\n",
        "\n",
        "print(\"\\n4. Asset Values Validation:\")\n",
        "# Check for negative asset values\n",
        "negative_assets = 0\n",
        "for col in ['residential_assets_value', 'commercial_assets_value', 'luxury_assets_value', 'bank_asset_value']:\n",
        "    neg_count = len(df[df[col] < 0])\n",
        "    if neg_count > 0:\n",
        "        print(f\"   Negative {col}: {neg_count:,}\")\n",
        "        negative_assets += neg_count\n",
        "\n",
        "if negative_assets == 0:\n",
        "    print(\"   All asset values are non-negative\")\n",
        "\n",
        "print(\"\\nData quality validation complete\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.5 Outlier Treatment Decision\n",
        "\n",
        "**Key Concept:** Decide how to handle outliers based on domain knowledge and impact analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üõ†Ô∏è  Outlier Treatment Strategy:\n",
            "===================================\n",
            "Strategy Decision Process:\n",
            "\n",
            "1. üìä CIBIL Score Outliers:\n",
            "   Outliers: 0 (0.0%)\n",
            "   Decision: KEEP - CIBIL scores outside normal range are realistic\n",
            "   Reason: Very high/low credit scores are legitimate and important for prediction\n",
            "\n",
            "2. üí∞ Income Outliers:\n",
            "   Outliers: 0 (0.0%)\n",
            "   Decision: KEEP - High/low incomes are realistic\n",
            "   Reason: Wide income variation is normal in financial data\n",
            "\n",
            "3. üè† Loan Amount Outliers:\n",
            "   Outliers: 0 (0.0%)\n",
            "   Decision: KEEP - Large loans are realistic\n",
            "   Reason: High-value loans (property, business) are legitimate\n",
            "\n",
            "4. üìÖ Loan Term Outliers:\n",
            "   Outliers: 0 (0.0%)\n",
            "   Decision: KEEP - Various loan terms are normal\n",
            "   Reason: Short-term and long-term loans both exist\n",
            "\n",
            "üéØ Final Decision:\n",
            "   ‚úÖ KEEP ALL OUTLIERS\n",
            "   üìù Reasoning:\n",
            "      - All outliers appear to be legitimate business cases\n",
            "      - Removing them might lose important information\n",
            "      - Machine learning algorithms can handle outliers\n",
            "      - We'll use robust scaling later to minimize impact\n",
            "\n",
            "üìä Final dataset size: 4,269 rows (no data removed)\n",
            "‚úÖ Data cleaning complete!\n"
          ]
        }
      ],
      "source": [
        "# Outlier treatment strategy\n",
        "print(\"Outlier Treatment Strategy:\")\n",
        "print(\"=\" * 30)\n",
        "\n",
        "# Create a copy for treatment comparison\n",
        "df_clean = df.copy()\n",
        "\n",
        "print(\"Strategy Decision Process:\")\n",
        "print(\"\\n1. CIBIL Score Outliers:\")\n",
        "cibil_outliers, cibil_lower, cibil_upper = detect_outliers_iqr(df, 'cibil_score')\n",
        "print(f\"   Outliers: {len(cibil_outliers)} ({(len(cibil_outliers)/len(df)*100):.1f}%)\")\n",
        "print(f\"   Decision: KEEP - CIBIL scores outside normal range are realistic\")\n",
        "print(f\"   Reason: Very high/low credit scores are legitimate and important for prediction\")\n",
        "\n",
        "print(\"\\n2. Income Outliers:\")\n",
        "income_outliers, income_lower, income_upper = detect_outliers_iqr(df, 'income_annum')\n",
        "print(f\"   Outliers: {len(income_outliers)} ({(len(income_outliers)/len(df)*100):.1f}%)\")\n",
        "print(f\"   Decision: KEEP - High/low incomes are realistic\")\n",
        "print(f\"   Reason: Wide income variation is normal in financial data\")\n",
        "\n",
        "print(\"\\n3. Loan Amount Outliers:\")\n",
        "loan_outliers, loan_lower, loan_upper = detect_outliers_iqr(df, 'loan_amount')\n",
        "print(f\"   Outliers: {len(loan_outliers)} ({(len(loan_outliers)/len(df)*100):.1f}%)\")\n",
        "print(f\"   Decision: KEEP - Large loans are realistic\")\n",
        "print(f\"   Reason: High-value loans (property, business) are legitimate\")\n",
        "\n",
        "print(\"\\n4. Loan Term Outliers:\")\n",
        "term_outliers, term_lower, term_upper = detect_outliers_iqr(df, 'loan_term')\n",
        "print(f\"   Outliers: {len(term_outliers)} ({(len(term_outliers)/len(df)*100):.1f}%)\")\n",
        "print(f\"   Decision: KEEP - Various loan terms are normal\")\n",
        "print(f\"   Reason: Short-term and long-term loans both exist\")\n",
        "\n",
        "print(\"\\nFinal Decision:\")\n",
        "print(\"   KEEP ALL OUTLIERS\")\n",
        "print(\"   Reasoning:\")\n",
        "print(\"      - All outliers appear to be legitimate business cases\")\n",
        "print(\"      - Removing them might lose important information\")\n",
        "print(\"      - Machine learning algorithms can handle outliers\")\n",
        "print(\"      - We'll use robust scaling later to minimize impact\")\n",
        "\n",
        "print(f\"\\nFinal dataset size: {len(df_clean):,} rows (no data removed)\")\n",
        "print(\"Data cleaning complete\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2 Complete\n",
        "\n",
        "### What We've Learned:\n",
        "\n",
        "1. **Missing Values**: No missing values found (rare in real data)\n",
        "2. **Outlier Detection**: Used IQR method to identify outliers systematically\n",
        "3. **Categorical Cleaning**: Removed extra spaces and standardized values\n",
        "4. **Data Validation**: Checked business logic and data consistency\n",
        "5. **Treatment Decisions**: Made informed decisions about outlier handling\n",
        "\n",
        "### Key Takeaways:\n",
        "\n",
        "- **Good Data Quality**: Our dataset is remarkably clean\n",
        "- **Domain Knowledge**: Used business understanding to make outlier decisions\n",
        "- **Systematic Approach**: Used statistical methods (IQR) for outlier detection\n",
        "- **Keep Outliers**: They represent legitimate business cases\n",
        "\n",
        "### Data Cleaning Principles We Applied:\n",
        "\n",
        "1. **Verify First**: Always double-check for missing values\n",
        "2. **Understand Context**: Use domain knowledge for decisions\n",
        "3. **Document Decisions**: Explain why you keep/remove data\n",
        "4. **Preserve Information**: Don't remove data unless absolutely necessary\n",
        "\n",
        "### Next Steps:\n",
        "**Step 3: Exploratory Data Analysis (EDA)** - We'll visualize our clean data to understand patterns and relationships\n",
        "\n",
        "---\n",
        "**Key Point**: Good data cleaning is about making informed decisions, not just following rules blindly.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
